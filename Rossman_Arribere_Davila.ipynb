{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico - Rossmann \n",
    "\n",
    "* Alumnos:\n",
    "    - Arribére, María Paz - 62280\n",
    "    - Dávila, Manuel - 62099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding, Input, Flatten, Concatenate, Dense, BatchNormalization, Activation, LeakyReLU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_normalized_data.fth')\n",
    "df_test = pd.read_feather('test_normalized_data.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
    "df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]\n",
    "len(df_train)/len(df), len(df_val)/len(df), len(df), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(sales, sales_):\n",
    "    return np.sqrt((((sales - sales_)/sales)**2).sum()/len(sales))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{\\hat{y}_i - y_i}{y_i}\\right)^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred)/y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_LR(X_columns, hidden_units=1):\n",
    "    inputs = []\n",
    "    activation = 'linear'\n",
    "    if hidden_units>1:\n",
    "        activation = 'relu'\n",
    "    for i, col in enumerate(X_columns):\n",
    "        inp = Input(shape=(X_train[i].shape[1],), name=f\"{col}_input\")\n",
    "        inputs.append(inp)\n",
    "    if len(X_columns)>1:\n",
    "        concat_out = Concatenate()(inputs)\n",
    "        dense_out = Dense(hidden_units, name='Dense', activation=activation)(concat_out)\n",
    "    else:\n",
    "        dense_out = Dense(hidden_units, name='Dense', activation=activation)(inputs[0])\n",
    "    if hidden_units>1:\n",
    "        dense_out = Dense(1, name='Dense_out')(dense_out)\n",
    "    model = Model(inputs, dense_out)\n",
    "    model.compile(optimizers.Adam(learning_rate=0.001), loss='mse', metrics=[rmspe, 'mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_embedings_NN(X_columns, hidden_units = 32, activation = 'relu'):\n",
    "    embed_outs = []\n",
    "    inputs = []\n",
    "    for i, col in enumerate(X_columns):\n",
    "        inp = Input(shape=(1,), name=f\"{col}_input\")\n",
    "        inputs.append(inp)\n",
    "        if col in embed_outs_dict:\n",
    "            embed_out = Embedding(len(np.unique(X_train[i])), embed_outs_dict[col], name=f\"{col}_embedding\", mask_zero=False)(inp)\n",
    "            out = Flatten(name=f\"{col}_flatten\")(embed_out)\n",
    "            embed_outs.append(out)\n",
    "        else:\n",
    "            embed_outs.append(inp)\n",
    "        \n",
    "    if len(X_columns)>1:\n",
    "        concat_out = Concatenate()(embed_outs)\n",
    "        dense_out = Dense(hidden_units, activation=activation)(concat_out)\n",
    "    else:\n",
    "        dense_out = Dense(hidden_units, activation=activation)(out)\n",
    "    out = Dense(1)(dense_out)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizers.Adam(learning_rate=0.001), loss='mse', metrics=[rmspe, 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_embed = True\n",
    "\n",
    "embed_outs_dict = {'Store': 2, 'DayOfWeek': 2, 'Promo': 5, 'Year': 2, 'Month': 2, 'Week': 2, 'Day': 2, \n",
    "                   'StoreType': 5, 'Assortment': 5, 'CompetitionDistance': 5, 'Promo2': 5,'PromoInterval': 3,\n",
    "                    'trend': 2, 'Precipitationmm': 2, 'Mean_TemperatureC':2, 'CloudCover':2, 'Events':2}\n",
    "\n",
    "X_columns = list(embed_outs_dict.keys())# + ['BeforeStateHoliday_bool', 'Max_TemperatureC'] # ['Precipitationmm']\n",
    "\n",
    "if final_train:\n",
    "    X_train = np.hsplit(df[X_columns].values, len(X_columns))\n",
    "    y_train = df['Sales_norm']\n",
    "else:\n",
    "    X_train = np.hsplit(df_train[X_columns].values, len(X_columns))\n",
    "    y_train = df_train['Sales_norm']\n",
    "    \n",
    "X_val = np.hsplit(df_val[X_columns].values, len(X_columns))\n",
    "X_test = np.hsplit(df_test[X_columns].values, len(X_columns))\n",
    "\n",
    "if not with_embed:\n",
    "    for i in range(len(X_train)):\n",
    "        X_train[i] = to_categorical(X_train[i])\n",
    "        X_val[i] = to_categorical(X_val[i])\n",
    "        X_test[i] = to_categorical(X_test[i])\n",
    "\n",
    "y_val = df_val['Sales_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_embed:\n",
    "    model = get_embedings_NN(X_columns)\n",
    "else:\n",
    "    model = get_keras_LR(X_columns, hidden_units=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model.compile(optimizers.Adam(learning_rate=0.001), loss='mse', metrics=[rmspe, 'mse'])\n",
    "cbs = [callbacks.ReduceLROnPlateau(monitor='val_rmspe', mode='min', verbose=1, patience=2), \n",
    "       callbacks.ModelCheckpoint('best_val_rmspe.keras', monitor='val_rmspe', mode='min', verbose=1, save_best_only=True),\n",
    "       callbacks.EarlyStopping(monitor='val_rmspe', mode='min', patience=5, verbose=1, restore_best_weights=True)]\n",
    "if final_train:\n",
    "    model.fit(X_train, y_train, epochs=epochs, callbacks=cbs)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_val_rmspe.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)*max_sales\n",
    "test_predictions[df_test['Open'] == 0] = 0\n",
    "\n",
    "sample_csv = pd.read_csv('rossmann/sample_submission.csv')\n",
    "sample_csv['Sales'] = test_predictions\n",
    "sample_csv.head()\n",
    "\n",
    "sample_csv.to_csv(f'submision_Arribere_Davila_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
